#!/usr/bin/env bash

readonly CHROM=11   # Chromosome 20 or 11
readonly S3_URL=http://1000genomes.s3.amazonaws.com/release/20130502/
readonly PED=integrated_call_samples.20130502.ALL.ped
readonly ALLVCF=ALL.chr${CHROM}.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz
readonly REFERENCE=hs37d5.fa.gz

readonly NSAMPLES=50
readonly NSITES=3
readonly ALLNSAMPLES=$((NSAMPLES*NSITES))

if [[ -z "$1" ]] || [[ ! -d "$1" ]] 
then
	>&2 echo "Usage: $0 /output/dir"
	>&2 echo "   eg, $0 /srv/ga4gh"
	>&2 echo "   invocation was: $0 $1 $2 $3"
	exit 1
fi

readonly OUTPUT_DIR="$1"

function wget_if_absent {
    local URL=$1
    local file=$2
    
    if [[ ! -f "${file}" ]]
    then
        echo "Wgetting ${URL}"
        wget -O "${file}" "$URL"
    fi
}

# use gsort/gzcat on OS X 
function gnusort {
    if hash gsort 2>/dev/null
    then
        gsort "$@"
    else
        sort "$@"
    fi
}

function gnuzipcat {
    if hash gzcat 2>/dev/null
    then
        gzcat "$@"
    else
        zcat "$@"
    fi
}

##
## Make sure we have the AWS cli installed 
##
have_aws_cli

mkdir -p "${OUTPUT_DIR}"

##
## Download metadata
##

wget_if_absent "${S3_URL}${ALLVCF}" "${ALLVCF}"
wget_if_absent "${S3_URL}${PED}" "${PED}"
wget_if_absent https://raw.githubusercontent.com/The-Sequence-Ontology/SO-Ontologies/master/so-xp-dec.obo "so-xp.obo"
wget_if_absent https://ga4ghstore.blob.core.windows.net/testing/gencode_v24lift37.db "gencode_v24lift37.db"
if [[ ! -f "${REFERENCE}" ]]
then
    wget_if_absent http://1000genomes.s3.amazonaws.com/technical/reference/human_g1k_v37.fasta.gz "${REFERENCE}"
    gunzip "${REFERENCE}"
    bgzip -f "${REFERENCE%.*}"
fi

##
## Choose our subset of samples
##

# pick NSAMPLES samples randomly from those reported in Chr22 VCF and sort them
readonly ALLRAWSAMPLES=$( gnuzipcat "${ALLVCF}" \
			| head -n 1000 \
			| grep CHROM \
			| cut -f10- -d $'\t' \
			| tr $'\t' $'\n' \
			| gnusort -R \
            | head -n "${ALLNSAMPLES}" )

ALLSAMPLES=""
SAMPLES=()
for site  in $( seq 1 $((NSITES)) )
do
    tmp=$( echo "${ALLRAWSAMPLES}" \
                         | awk -v site="$site" -v N="$NSAMPLES" 'NR>=(site-1)*N && NR <(site)*N' \
                         | gnusort \
                         | tr $'\n' , )
    ALLSAMPLES="${ALLSAMPLES}${tmp}"
    SAMPLES[$site]=${tmp%?}   # remove last character
    SAMPLES[$site]=${SAMPLES[$site]%?}   # remove last character
    echo "$site"
    echo "${SAMPLES[$site]}"
done
ALLSAMPLES="${ALLSAMPLES%?}"

###
### Strip out the other samples, and variants not seen in our samples
###

mkdir -p "${OUTPUT_DIR}/all_samples"
tmpfile="${OUTPUT_DIR}/all_samples/chr${CHROM}.unsampled.vcf.gz"
ln -s "$ALLVCF" "$tmpfile"
finalfile="${OUTPUT_DIR}/all_samples/chr${CHROM}.vcf"
bcftools view --force-samples -s "${ALLSAMPLES}" "${tmpfile}" \
     | bcftools view -i 'GT="1" || GT="1|1" || GT="0|1" || GT="1|0"' -o "${finalfile}"

##
## Now create each site's data set 
##

for site in $( seq 1 $NSITES )
do
    sitedir="${OUTPUT_DIR}/sites/${site}"
    mkdir -p "${sitedir}"

    cp "${REFERENCE}" "${sitedir}/${REFERENCE}"
    cp so-xp.obo "${sitedir}/so-xp.obo"
    cp "gencode_v24lift37.db" "${sitedir}/gencode_v24lift37.db"

    ## 
    ## final subset (and tabix) of the VCFs
    ##
    mkdir -p "${sitedir}/vcfs"
    tmpfile="${OUTPUT_DIR}/all_samples/chr${CHROM}.vcf"
    finalfile="${sitedir}/vcfs/chr${CHROM}.vcf"
    bcftools view --force-samples -s "${SAMPLES[$site]}" "${tmpfile}" \
         | bcftools view -i 'GT="1" || GT="1|1" || GT="0|1" || GT="1|0"' -o "${finalfile}"
    bgzip -f "${finalfile}"
    tabix -p vcf "${finalfile}.gz"

    ##
    ## Get the relevant BAMs
    ##
    mkdir -p "${sitedir}/bams"
    samples=$( echo "${SAMPLES[$site]}" | tr ',' ' ' )
    for sample in $samples
    do
        bam="ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/${sample}/alignment/${sample}.chrom${CHROM}.ILLUMINA.bwa.GBR.low_coverage.20130415.bam"
        wget_if_absent "${bam}" "${sitedir}/bams/${sample}.chr${CHROM}.bam"
        wget_if_absent "${bam}.bai" "${sitedir}/bams/${sample}.chr${CHROM}.bam.bai"
    done

    # create the registry
    echo "Registry"
    registry="${sitedir}/registry.db"
    if [[ ! -f ${registry} ]]
    then
        ga4gh_repo init "${registry}"
        ga4gh_repo add-dataset "${registry}" 1kgenomes \
           --description "Variants from the 1000 Genomes project and GENCODE genes annotations"
    fi

    # Add reference
    echo "Reference"
    ga4gh_repo add-referenceset "${registry}" "${sitedir}/${REFERENCE}" \
          -d "NCBI37 assembly of the human genome" --ncbiTaxonId 9606 --name NCBI37 \
            --sourceUri "${S3_URL}/../../technical/reference/human_g1k_v37.fasta.gz"

    # Add sequence ontology
    echo "Ontology"
    ga4gh_repo add-ontology "${registry}" "${sitedir}/so-xp.obo" -n so-xp

    # Add sequence annotations
    echo "Gencode"
    ga4gh_repo add-featureset "${registry}" "1kgenomes" "${sitedir}/gencode_v24lift37.db" \
            --referenceSetName NCBI37 --ontologyName so-xp

    ga4gh_repo add-variantset "${registry}" 1kgenomes "${sitedir}/vcfs" \
            --name phase3-release --referenceSetName NCBI37

    for bamfile in "${sitedir}/bams/"*bam
    do
        ga4gh_repo add-readgroupset "${registry}" 1kgenomes "${bamfile}" \
                --name phase3-release --referenceSetName NCBI37 -I "${bamfile}.bai"
    done
done
